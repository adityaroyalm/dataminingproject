{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dicom in /usr/local/envs/py3env/lib/python3.5/site-packages\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 9.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pydicom in /usr/local/envs/py3env/lib/python3.5/site-packages\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 9.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: keras in /usr/local/envs/py3env/lib/python3.5/site-packages\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/envs/py3env/lib/python3.5/site-packages (from keras)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/envs/py3env/lib/python3.5/site-packages (from keras)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/envs/py3env/lib/python3.5/site-packages (from keras)\n",
      "Requirement already satisfied: pyyaml in /usr/local/envs/py3env/lib/python3.5/site-packages (from keras)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 9.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: h5py in /usr/local/envs/py3env/lib/python3.5/site-packages\n",
      "Requirement already satisfied: numpy>=1.7 in /usr/local/envs/py3env/lib/python3.5/site-packages (from h5py)\n",
      "Requirement already satisfied: six in /usr/local/envs/py3env/lib/python3.5/site-packages (from h5py)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 9.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "                                 id  cancer\n",
      "0  4a1391269629d20359325873d11413c9     0.0\n",
      "1  3b908e86ea0f7cbd05dd8e0ea6d45d79     0.0\n",
      "2  3c5a0fc6890a1f84211cf8a75c1b83c4     0.0\n",
      "3  0a38e7597ca26f9374f8ea2770ba870d     0.0\n",
      "4  3b78adbbe463aba48bf29613ca37b2ea     0.0\n",
      "5  7bfba4540956c0b2c5b78b3623a4855d     1.0\n",
      "6  00cba091fa4ad62cc3200a657aeb957e     0.0\n",
      "7  0a0c32c9e08cc2ea76a71649de56be6d     0.0\n",
      "8  3c73f5597780b7312b380373fb897f40     0.0\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'train' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-85cbc63e2258>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0mmsa_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0mmsa_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m \u001b[0mmsa_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msecond_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-85cbc63e2258>\u001b[0m in \u001b[0;36msecond_func\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    189\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marray_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m       \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m       \u001b[0mvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marray_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'train' referenced before assignment"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import glob\n",
    "\n",
    "!pip install dicom\n",
    "!pip install pydicom\n",
    "import dicom\n",
    "import scipy.ndimage\n",
    "from __future__ import division\n",
    "import pydicom\n",
    "from io import BytesIO\n",
    "import google.datalab.storage as storage\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import filters\n",
    "from scipy.ndimage.interpolation import rotate\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "!pip install keras\n",
    "!pip install h5py\n",
    "import h5py\n",
    "import keras \n",
    "from keras import layers \n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import BatchNormalization,Conv2D\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from keras.layers import Flatten,Dense\n",
    "from keras.utils import to_categorical\n",
    "class msa:\n",
    "  def initialize(self):\n",
    "    replay=0\n",
    "    replay2=0\n",
    "    #%gcs read --o \"gs://msadata/stage1_labels.csv/stage1_labels.csv\" --variable df\n",
    "    bucket = storage.Bucket('msadata')\n",
    "    obj = bucket.object('stage1_labels.csv/stage1_labels.csv')\n",
    "    csv_file=obj.read_stream()\n",
    "    df=pd.read_csv(BytesIO(csv_file))\n",
    "    #print(df)\n",
    "    #y=np.array([int(x) for x in df['cancer'].values])\n",
    "    df=df.sort_values(['cancer'])\n",
    "    total=list()\n",
    "    train=list()\n",
    "    valid=list()\n",
    "    test=list()\n",
    "    for o in storage.Bucket('msadata').objects(prefix='test2',delimiter=''):\n",
    "        total.append(str(o.key).split('/')[1])\n",
    "    total=list(set(total))\n",
    "    total=sorted(total)\n",
    "    y=np.array(df['cancer'])\n",
    "    total=pd.DataFrame(total,columns=['id'])\n",
    "    total=total.merge(df,how='left',on='id')   \n",
    "    total_na=total.isnull().sum()\n",
    "    total=total.fillna(0)\n",
    "    if total.shape[1]>2:\n",
    "        total.drop(columns=[x for x in t.columns[2:]],inplace=True)\n",
    "    for x in range(2,10):\n",
    "      if len(total)%x==0:\n",
    "        ratio=1/x\n",
    "        break\n",
    "      else:\n",
    "        pass\n",
    "    for x in range(2,10):\n",
    "      if len(total)%x==0:\n",
    "        ratio=1/x\n",
    "        break\n",
    "      else:\n",
    "        pass\n",
    "    train,test=train_test_split(total.iloc[1:,:],test_size=ratio)\n",
    "    for x in range(2,10):\n",
    "      if len(train)%x==0:\n",
    "        ratio=1/x\n",
    "        break\n",
    "      else:\n",
    "        pass\n",
    "    valid,test=train_test_split(test,test_size=ratio)\n",
    "    train.reset_index(drop=True,inplace=True)\n",
    "    test.reset_index(drop=True,inplace=True)\n",
    "    valid.reset_index(drop=True,inplace=True)\n",
    "    train.reset_index(drop=True,inplace=True)\n",
    "    test.reset_index(drop=True,inplace=True)\n",
    "    valid.reset_index(drop=True,inplace=True)\n",
    "    repeat='notfoo'\n",
    "    if repeat=='foo':\n",
    "      model = load_model('my_model.h5')\n",
    "    else:\n",
    "      model=Sequential()\n",
    "      model.add(Conv2D(80,(10),padding='same',activation='relu',data_format='channels_first',input_shape=(150,512,512)))\n",
    "      model.add(Conv2D(50,(10),padding='same',activation='relu',data_format='channels_first'))\n",
    "      model.add(Conv2D(1,(1),padding='same',activation='relu',data_format='channels_first'))\n",
    "      model.add(Flatten())\n",
    "      model.add(Dense(2,activation='relu'))\n",
    "      model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])\n",
    "      i=0 \n",
    "    print(train)\n",
    "  def array_generator(self,train):\n",
    "    if train.loc[0,'id']==test.loc[0,'id']:\n",
    "      check='foo'\n",
    "    #print(88)\n",
    "    else:\n",
    "      check='notfoo'\n",
    "    train_y=train['cancer'].values\n",
    "    train_y=to_categorical(train_y,num_classes=2)\n",
    "    while 1: \n",
    "      y=list()\n",
    "    \n",
    "      ordered_position=list()\n",
    "      plan0=list()\n",
    "      b=list()\n",
    "      for i in range(1,len(train)):\n",
    "        slices=list()\n",
    "        patient=list()\n",
    "        position=list()\n",
    "        patient_images=list()\n",
    "        patient=[o.key for o in storage.Objects('msadata',prefix='test2/'+str(train.loc[i,'id'])+'/',delimiter='')]\n",
    "        for j in range(len(patient)):\n",
    "          bucket = storage.Bucket('msadata')\n",
    "          obj = bucket.object(patient[j])\n",
    "          dicom_file=obj.read_stream()\n",
    "          df=dicom.read_file(BytesIO(dicom_file))\n",
    "          position.append(df.SliceLocation)\n",
    "        sor=sorted(position)\n",
    "        ran=[sor.index(x) for x in position]\n",
    "        o=0\n",
    "        v=[0 for x in range(len(patient))]\n",
    "        for x in ran:\n",
    "          #print(x)\n",
    "          v[x]=patient[o]\n",
    "          o=o+1\n",
    "        patient=v\n",
    "       # print(position)\n",
    "        for j in range(len(patient)):\n",
    "          bucket = storage.Bucket('msadata')\n",
    "          obj = bucket.object(patient[j])\n",
    "          dicom_file=obj.read_stream()\n",
    "          df=dicom.read_file(BytesIO(dicom_file))\n",
    "          ordered_poistion=df.ImageOrientationPatient\n",
    "          pixel_Array=df.pixel_array\n",
    "          pixel_Array=pixel_Array*ordered_poistion[0]+pixel_Array*ordered_poistion[1]+pixel_Array*ordered_poistion[2]\n",
    "          val=filters.threshold_otsu(pixel_Array)\n",
    "          mask=pixel_Array>val\n",
    "          pixel_Array=mask*pixel_Array\n",
    "          slices.append(pixel_Array)\n",
    "          if j>0:\n",
    "              #print(np.abs(np.array([0,0,df.SliceLocation],dtype=np.float)-previous))\n",
    "              df.SliceThickness=list(np.abs(np.array([df.SliceLocation,0,0],dtype=np.float)-previous))\n",
    "              #print(df.SliceThickness)\n",
    "          else:\n",
    "              #print(np.abs([0,0,df.SliceLocation]))\n",
    "              df.SliceThickness=list(np.abs([df.SliceLocation,0,0]))\n",
    "              #print(df.SliceThickness)\n",
    "          previous=np.array([df.SliceLocation,0,0],dtype=np.float)\n",
    "        threed_array=np.stack([x for x in slices],axis=0)\n",
    "        #print(threed_array.shape)\n",
    "        adjust=(np.array([df.PixelSpacing[0]]*3,dtype=np.float)+np.array(df.SliceThickness,dtype=np.float))/np.array([1,1,1])\n",
    "        #print(adjust)\n",
    "        #threed_array=zoom(threed_array,np.round(adjust*threed_array.shape)/threed_array.shape)\n",
    "        #print(threed_array.shape)\n",
    "        threed_array=np.expand_dims(threed_array,axis=0)\n",
    "       # print(threed_array.shape)\n",
    "        if threed_array.shape[1]>=150:\n",
    "          threed_array=threed_array[:,:150,:,:]\n",
    "        else:\n",
    "          temp=threed_array\n",
    "          m=threed_array.shape[1]\n",
    "          threed_array=np.zeros((1,150,512,512))\n",
    "          threed_array[0,:m,:,:]=temp\n",
    "        if check=='foo':\n",
    "          #print('test')\n",
    "          yield(threed_array)\n",
    "          model.save('my_model.h5') \n",
    "          global replay\n",
    "          replay=replay+1\n",
    "        else:\n",
    "          #print('train')\n",
    "          #print(i)\n",
    "          #print(np.expand_dims(train_y[i],0))\n",
    "          yield(threed_array,np.expand_dims(train_y[i],0))\n",
    "          model.save('my_model.h5') \n",
    "          global replay2\n",
    "          replay2=replay2+1\n",
    "  def second_func(self):\n",
    "    if replay>=1 or replay2>=1:\n",
    "      model=load_model('my_model.h5')\n",
    "      train=train[replay:,:]\n",
    "      valid=valid[replay2:,:]\n",
    "      model.fit_generator(array_generator(train),validation_data=array_generator(valid),validation_steps=len(valid),use_multiprocessing=False,steps_per_epoch=len(train),epochs=2)\n",
    "    else:\n",
    "      train=train[0,:]\n",
    "      valid=valid[0,:]\n",
    "      model.fit_generator(array_generator(train),validation_data=array_generator(valid),validation_steps=len(valid),use_multiprocessing=False,steps_per_epoch=len(train),epochs=2)\n",
    "msa_instance=msa()\n",
    "msa_instance.initialize()\n",
    "msa_instance.second_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'msa' object has no attribute 'second_func'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-30845fb8bd42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0mmsa_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0mmsa_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m \u001b[0mmsa_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msecond_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'msa' object has no attribute 'second_func'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.evaluate_generator(array_generator(train),steps=len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_y=train['cancer'].values\n",
    "train_y=to_categorical(train_y,num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
